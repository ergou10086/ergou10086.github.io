<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>参数估计之点估计—矩估计法和最大似然估计法 | ErgouTree's Blog</title><meta name="author" content="ErgouTree"><meta name="copyright" content="ErgouTree"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="参数估计之点估计 什么是参数估计 首先，什么是参数估计呢？ 之前我们其实已经了解到很多种分布类型了，比如正态分布、均匀分布、泊松分布等。拿正态分布举例，决定正态分布的有两个参数：均值和方差。 因此，参数就是决定分布的关键性数据。知道了参数，也就是知道了分布的详细内容。 总体的分布类别如果我们知道了，是不是只要知道分布的参数，就能知道总体的分布详情？ 所以说，用样本的数据来构造函数（即统">
<meta property="og:type" content="article">
<meta property="og:title" content="参数估计之点估计—矩估计法和最大似然估计法">
<meta property="og:url" content="https://ergou10086.github.io/posts/5644.html">
<meta property="og:site_name" content="ErgouTree&#39;s Blog">
<meta property="og:description" content="参数估计之点估计 什么是参数估计 首先，什么是参数估计呢？ 之前我们其实已经了解到很多种分布类型了，比如正态分布、均匀分布、泊松分布等。拿正态分布举例，决定正态分布的有两个参数：均值和方差。 因此，参数就是决定分布的关键性数据。知道了参数，也就是知道了分布的详细内容。 总体的分布类别如果我们知道了，是不是只要知道分布的参数，就能知道总体的分布详情？ 所以说，用样本的数据来构造函数（即统">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ergou10086.github.io/images/posts/cover_security.jpg">
<meta property="article:published_time" content="2025-06-26T13:01:47.000Z">
<meta property="article:modified_time" content="2025-06-27T06:09:44.465Z">
<meta property="article:author" content="ErgouTree">
<meta property="article:tag" content="学习类">
<meta property="article:tag" content="数学">
<meta property="article:tag" content="概率论与数理统计">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ergou10086.github.io/images/posts/cover_security.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "参数估计之点估计—矩估计法和最大似然估计法",
  "url": "https://ergou10086.github.io/posts/5644.html",
  "image": "https://ergou10086.github.io/images/posts/cover_security.jpg",
  "datePublished": "2025-06-26T13:01:47.000Z",
  "dateModified": "2025-06-27T06:09:44.465Z",
  "author": [
    {
      "@type": "Person",
      "name": "ErgouTree",
      "url": "https://github.com/ergou10086"
    }
  ]
}</script><link rel="shortcut icon" href="/img/pi.ico"><link rel="canonical" href="https://ergou10086.github.io/posts/5644.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?https://hm.baidu.com/hm.js?a6ab1b78e2c6320b664f31e8b9bf0e36";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '参数估计之点估计—矩估计法和最大似然估计法',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css"><svg aria-hidden="true" style="position:absolute; overflow:hidden; width:0; height:0"><symbol id="icon-sun" viewBox="0 0 1024 1024"><path d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z" fill="#FFD878" p-id="8420"></path><path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z" fill="#FFE4A9" p-id="8421"></path><path d="M512 109.248L626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z" fill="#4D5152" p-id="8422"></path><path d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z" fill="#4D5152" p-id="8423"></path></symbol><symbol id="icon-moon" viewBox="0 0 1024 1024"><path d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z" fill="#FFB531" p-id="11345"></path><path d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z" fill="#030835" p-id="11346"></path></symbol></svg><link rel="stylesheet" href="/css/custom.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><script>window.paceOptions = {
  restartOnPushState: false
}

btf.addGlobalFn('pjaxSend', () => {
  Pace.restart()
}, 'pace_restart')

</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/themes/blue/pace-theme-minimal.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg" style="background: linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/arp.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">148</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">82</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">55</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> Gallery</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fas fa-game"></i><span> GalGame</span></a></li><li><a class="site-page child" href="/video/"><i class="fa-fw fas fa-video"></i><span> Video</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><span> Random</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/images/posts/cover_security.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">ErgouTree's Blog</span></a><a class="nav-page-title" href="/"><span class="site-name">参数估计之点估计—矩估计法和最大似然估计法</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> Gallery</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fas fa-game"></i><span> GalGame</span></a></li><li><a class="site-page child" href="/video/"><i class="fa-fw fas fa-video"></i><span> Video</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="javascript:randomPost();"><span> Random</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div><div id="randomPost"><a class="site-page social-icon search" href="javascript:;" onclick="randomPost()" title="随机访问一篇文章"><i class="fas fa-circle-notch fa-fw"></i></a></div></nav><div id="post-info"><h1 class="post-title">参数估计之点估计—矩估计法和最大似然估计法<a class="post-edit-link" href="https://github.com/ergou10086/ergou10086.github.io/edit/main/source/_posts/_posts/参数估计之点估计—矩估计法和最大似然估计法.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-06-26T13:01:47.000Z" title="发表于 2025-06-26 21:01:47">2025-06-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-06-27T06:09:44.465Z" title="更新于 2025-06-27 14:09:44">2025-06-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6%E7%B1%BB/">数学类</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6%E7%B1%BB/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/">概率论与数理统计</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">6.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>25分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/posts/5644.html#post-comment"><span class="gitalk-comment-count"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h2 id="参数估计之点估计">参数估计之点估计</h2>
<h3 id="什么是参数估计">什么是参数估计</h3>
<p>首先，什么是参数估计呢？</p>
<p>之前我们其实已经了解到很多种分布类型了，比如正态分布、均匀分布、泊松分布等。拿正态分布举例，决定正态分布的有两个参数：均值和方差。</p>
<p>因此，<strong>参数</strong>就是决定分布的关键性数据。知道了参数，也就是知道了分布的详细内容。</p>
<p>总体的分布类别如果我们知道了，是不是只要知道分布的参数，就能知道总体的分布详情？</p>
<p>所以说，用样本的数据来构造函数（即统计量），来估计总体参数，这就是参数估计。</p>
<h3 id="估计量">估计量</h3>
<h4 id="定义">定义</h4>
<p>估计量是样本的统计量，用于估计总体未知参数。它是一个<strong>随机变量</strong>，因为其值依赖于随机样本。</p>
<p>若总体参数为 <span class="math inline"><em>θ</em></span>，表示总体<span class="math inline"><em>X</em></span>的待估计参数，其中 <span class="math inline"><em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X</em><sub><em>n</em></sub></span>
是来自总体的样本，则其中的一个估计量记作 <span class="math inline"><em>θ̂</em> = <em>θ̂</em>(<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X</em><sub><em>n</em></sub>)</span>来估计<span class="math inline"><em>θ</em></span>，则称 <span class="math inline"><em>θ̂</em></span> 为 <span class="math inline"><em>θ</em></span> 的估计量</p>
<h4 id="理解">理解</h4>
<p>用于估计总体参数的 <strong>随机变量</strong>
，是基于样本构造的、对总体参数进行估计的 “规则 / 公式” 。</p>
<p>它本身是一种统计量（由样本数据计算得到），因样本具有随机性，所以估计量是随机变量，会随样本不同而变化。</p>
<p>比如：用 “样本均值 <span class="math inline">$\bar{X} =
\frac{1}{n}\sum_{i = 1}^{n}X_i$</span>” 估计 “总体均值 <span class="math inline"><em>μ</em></span>” ，这里的 <span class="math inline"><em>X̄</em></span> 就是总体均值 <span class="math inline"><em>μ</em></span>
的一个<strong>估计量</strong>；同理，样本方差、样本比例等也可作为对应总体参数的估计量。</p>
<h3 id="估计值">估计值</h3>
<h4 id="定义-1">定义</h4>
<p>而继续上述估计量的说法</p>
<p>若总体参数为 <span class="math inline"><em>θ</em></span>，表示总体<span class="math inline"><em>X</em></span>的待估计参数，其中 <span class="math inline"><em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X</em><sub><em>n</em></sub></span>
是来自总体的样本，则其中的一个估计量记作 <span class="math inline"><em>θ̂</em> = <em>θ̂</em>(<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X</em><sub><em>n</em></sub>)</span>来估计
<span class="math inline"><em>θ</em></span>，则称 <span class="math inline"><em>θ̂</em></span> 为 <span class="math inline"><em>θ</em></span> 的估计量，对应于样本<span class="math inline">(<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X</em><sub><em>n</em></sub>)</span>的一次观测值，估计量
<span class="math inline"><em>θ̂</em></span> 的值 <span class="math inline"><em>θ̂</em>(<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X</em><sub><em>n</em></sub>)</span>
称为 <span class="math inline"><em>θ</em></span>
的估计值，并且仍然简记为 <span class="math inline"><em>θ̂</em></span></p>
<p>简单说法：对于样本观测值 <span class="math inline"><em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, …, <em>x</em><sub><em>n</em></sub></span>，估计值为
<span class="math inline"><em>θ̂</em> = <em>T</em>(<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, …, <em>x</em><sub><em>n</em></sub>)</span>。</p>
<h4 id="理解-1">理解</h4>
<p>估计量是<strong>函数形式</strong>（如样本均值 <span class="math inline">$\bar{X} = \frac{1}{n}\sum_{i=1}^n
X_i$</span>），而估计值是函数代入样本后的<strong>具体数值</strong>（如
<span class="math inline"><em>x̄</em> = 5.2</span>）。</p>
<p>所以估计值是基于某一次抽样的样本，把数据代入估计量的公式，算出的具体值。由于样本确定，估计值是固定数。</p>
<p>比如：抽取一组样本，计算得样本均值 <span class="math inline"><em>x̄</em> = 80</span>（这里用小写 <span class="math inline"><em>x̄</em></span> 表示具体数值 ），那么 80
就是总体均值 <span class="math inline"><em>μ</em></span>
的<strong>估计值</strong>；若换一组样本，计算出 <span class="math inline"><em>x̄</em> = 82</span>，则此时估计值就是 82 。</p>
<h3 id="何为点估计">何为点估计</h3>
<p><strong>点估计</strong>就是用一个数值对总体参数给出估计；</p>
<p>利用<strong>样本数据计算一个数值</strong>，来直接估计总体未知参数的具体值。</p>
<p>用样本的 “某个特征值” 作为总体对应参数的
“最佳猜测”，结果是一个确定的数值（点），而非区间。</p>
<p>此时，<strong>总体与样本的关系</strong>如下</p>
<ul>
<li>总体参数（如 <span class="math inline"><em>μ</em>, <em>σ</em><sup>2</sup>, <em>p</em></span>）通常未知，需通过抽样获取样本（如
<span class="math inline"><em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X</em><sub><em>n</em></sub></span>）。</li>
<li>点估计的目标：用样本构造一个统计量（如 <span class="math inline"><em>X̄</em>, <em>S</em><sup>2</sup>, <em>P̂</em></span>），将其计算值作为总体参数的近似。</li>
</ul>
<p>点估计的方法基本如下</p>
<ul>
<li>根据问题选矩估计、极大似然估计等构造估计量；</li>
<li>用样本数据计算估计值</li>
<li>用无偏性、有效性等标准评估估计的可靠性。</li>
</ul>
<h2 id="矩估计法">矩估计法</h2>
<h3 id="什么是矩估计呢">什么是矩估计呢</h3>
<p><strong>矩估计</strong>比较好理解，就是<strong>用样本矩直接匹配总体矩</strong>，从而估计未知参数。<br>
- 样本矩：从实际数据计算出的统计量（如样本均值、方差）。<br>
- 总体矩：理论分布的数字特征（如期望、方差）。<br>
- 尽量选取低阶矩 - 总体矩必须含有未知参数。</p>
<p>啥意思呢？就是我们将样本的矩计算出来，直接作为总体的矩即可。</p>
<p>例如：</p>
<ul>
<li>总体均值 <span class="math inline"><em>μ</em></span>
的矩估计量是样本均值 <span class="math inline"><em>X̄</em></span>；总体方差 <span class="math inline"><em>σ</em><sup>2</sup></span> 的矩估计量是 <span class="math inline">$\frac{1}{n}\sum(X_i -
\bar{X})^2$</span>（注意：与无偏估计的样本方差 <span class="math inline">$S^2 = \frac{1}{n-1}\sum(X_i - \bar{X})^2$</span>
不同）。</li>
</ul>
<p>矩法估计的重点就在于“矩”字，我们知道矩是概率分布的一种数字特征，可以分为原点矩和中心矩两种。对于随机变量<span class="math inline"><em>X</em></span>而言，其 <span class="math inline"><em>k</em></span> 阶原点矩和 <span class="math inline"><em>k</em></span> 阶中心矩为</p>
<p>离散的 k 阶原点矩： <span class="math display"><em>E</em>[<em>X</em><sup><em>k</em></sup>] = ∑<sub><em>i</em></sub><em>x</em><sub><em>i</em></sub><sup><em>k</em></sup> ⋅ <em>P</em>(<em>X</em> = <em>x</em><sub><em>i</em></sub>)</span>
离散的 k 阶中心矩： <span class="math display">$$
\mu_k = \sum_{i=1}^{n} (x_i - EX)^k p_i
$$</span> 连续的 k 阶原点矩 <span class="math display"><em>E</em>[<em>X</em><sup><em>k</em></sup>] = ∫<sub>−∞</sub><sup>∞</sup><em>x</em><sup><em>k</em></sup><em>f</em>(<em>x</em>) <em>d</em><em>x</em></span>
连续的 k 阶中心距 <span class="math display"><em>μ</em><sub><em>k</em></sub> = ∫<sub>−∞</sub><sup>+∞</sup>(<em>x</em> − <em>E</em><em>X</em>)<sup><em>k</em></sup><em>f</em>(<em>x</em>) <em>d</em><em>x</em></span>
特别地，一阶原点矩就是随机变量的期望，二阶中心矩就是随机变量的方差，由于<span class="math inline"><em>E</em>(<em>X</em> − <em>E</em>(<em>X</em>)) = 0</span>，所以我们不定义一阶中心矩。</p>
<h3 id="具体求法">具体求法</h3>
<p>设总体 <span class="math inline"><em>X</em></span> 的分布函数为 <span class="math inline"><em>F</em>(<em>x</em> : <em>θ</em><sub>1</sub>, <em>θ</em><sub>2</sub>, …, <em>θ</em><sub><em>n</em></sub>)</span>，其中<span class="math inline"><em>θ</em><sub>1</sub>, <em>θ</em><sub>2</sub>, …, <em>θ</em><sub><em>n</em></sub></span>，是
<span class="math inline"><em>k</em></span> 个待估参数，<span class="math inline">(<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, ⋯, <em>X</em><sub><em>n</em></sub>)</span>是取自<span class="math inline"><em>X</em></span>的样本。假设总体<span class="math inline"><em>X</em></span>的<span class="math inline"><em>k</em></span>阶原点矩<span class="math inline"><em>E</em>(<em>X</em><sup><em>k</em></sup>)</span>存在，则总体<span class="math inline"><em>X</em></span>的<span class="math inline"><em>j</em></span>阶原点矩 <span class="math display"><em>a</em><sub><em>j</em></sub>(<em>θ</em><sub>1</sub>, <em>θ</em><sub>2</sub>, ⋯, <em>θ</em><sub><em>k</em></sub>) = <em>E</em>(<em>X</em><sup><em>j</em></sup>),  1 ≤ <em>j</em> ≤ <em>k</em></span>
样本<span class="math inline">(<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, ⋯, <em>X</em><sub><em>n</em></sub>)</span>的
$j $ 阶原点矩为 <span class="math display">$$
A_j = \frac{1}{n} \sum_{i = 1}^n X_i^j,\quad 1 \leq j \leq k
$$</span> 令样本矩等于对应的总体矩，可得 <span class="math inline"><em>k</em></span> 个方程 <span class="math display"><em>a</em><sub><em>j</em></sub>(<em>θ</em><sub>1</sub>, <em>θ</em><sub>2</sub>, ⋯, <em>θ</em><sub><em>k</em></sub>) = <em>A</em><sub><em>j</em></sub>,  1 ≤ <em>j</em> ≤ <em>k</em>  (7.1)</span>
求解上述方程组，得到一组解<span class="math inline"><em>θ̂</em><sub>1</sub>, <em>θ̂</em><sub>2</sub>, ⋯, <em>θ̂</em><sub><em>k</em></sub></span>，以此作为待估参数<span class="math inline"><em>θ</em><sub>1</sub>, <em>θ</em><sub>2</sub>, ⋯, <em>θ</em><sub><em>k</em></sub></span>的矩估计量。</p>
<p>完全可以拆分成如下形式，好理解一些</p>
<ol type="1">
<li><strong>计算样本矩</strong>：根据样本数据计算前 <span class="math inline"><em>k</em></span> 阶矩（通常只需低阶矩）。
<ul>
<li>例如：样本均值 <span class="math inline">$\bar{X} =
\frac{1}{n}\sum_{i=1}^n X_i$</span>（一阶原点矩），样本方差 <span class="math inline">$S^2 = \frac{1}{n}\sum_{i=1}^n (X_i -
\bar{X})^2$</span>（二阶中心矩）。</li>
</ul></li>
<li><strong>设定总体矩方程</strong>：将总体矩表示为待估参数 <span class="math inline"><em>θ</em></span> 的函数。
<ul>
<li>例如：若总体服从 <span class="math inline"><em>N</em>(<em>μ</em>, <em>σ</em><sup>2</sup>)</span>，则一阶总体矩
<span class="math inline"><em>E</em>(<em>X</em>) = <em>μ</em></span>，二阶中心矩
$ D(X) = ^2$。</li>
</ul></li>
<li><strong>联立方程求解</strong>：令样本矩 = 总体矩，解出参数 <span class="math inline"><em>θ</em></span>。
<ul>
<li>例如：
<ul>
<li><span class="math inline"><em>μ̂</em> = <em>X̄</em></span>（用样本均值估计总体均值）<br>
</li>
<li><span class="math inline">$\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^n
(X_i - \bar{X})^2$</span>（用样本二阶中心矩估计总体方差）</li>
</ul></li>
</ul></li>
</ol>
<h3 id="示例">示例</h3>
<h4 id="泊松分布的矩估计">泊松分布的矩估计</h4>
<p>设 <span class="math inline"><em>X</em> ∼ Poisson(<em>λ</em>)</span>，参数 <span class="math inline"><em>λ</em></span> 未知， <span class="math inline"><em>λ</em> &gt; 0</span>，<span class="math inline"><em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X</em><sub><em>n</em></sub></span>为取自<span class="math inline"><em>X</em></span>的样本，求待估参数<span class="math inline"><em>λ</em></span>的矩估计：</p>
<p>因为只有一个待估计参数，所以只要列出总体一阶原点矩等于样本一阶原点矩的方程就行，</p>
<ol type="1">
<li>总体一阶矩：<span class="math inline">$E(X) =
\int_{-\infty}^{\infty} x f(x; \lambda) \, dx =
\frac{1}{\lambda}$</span>。<br>
</li>
<li>样本一阶矩：<span class="math inline">$\bar{X} = \frac{1}{n}\sum
X_i$</span>。<br>
</li>
<li>矩估计：<span class="math inline">$\frac{1}{\lambda} = \frac{1}{n}
\sum_{i=1}^{n} X_i = \overline{X}$</span>（用样本均值估计 <span class="math inline"><em>λ</em></span>）。</li>
</ol>
<p>解得 <span class="math inline"><em>λ</em></span> 的矩估计为$ = $</p>
<h4 id="试求总体均值和方差的矩估计">试求总体均值和方差的矩估计</h4>
<p>设总体均值为<span class="math inline"><em>μ</em></span>，方差为<span class="math inline"><em>σ</em><sup>2</sup></span>，<span class="math inline">(<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, ⋯, <em>X</em><sub><em>n</em></sub>)</span>为取自总体<span class="math inline"><em>X</em></span>的样本。因为待估参数为<span class="math inline"><em>μ</em></span>, <span class="math inline"><em>σ</em><sup>2</sup></span>两个，故由矩估计法得方程组
<span class="math display">$$
\begin{cases}
a_1 = A_1, \\
a_2 = A_2,
\end{cases}
$$</span> 即 <span class="math display">$$
\begin{cases}
\mu = \frac{1}{n} \sum_{i = 1}^{n} X_i = \overline{X}, \\
\mu^2 + \sigma^2 = \frac{1}{n} \sum_{i = 1}^{n} X_i^2,
\end{cases}
$$</span> 解得 <span class="math display">$$
\begin{cases}
\hat{\mu} = \overline{X}, \\
\hat{\sigma}^2 = \frac{1}{n} \sum_{i = 1}^{n} X_i^2 - \overline{X}^2 =
\frac{1}{n} \sum_{i = 1}^{n} (X_i - \overline{X})^2 \stackrel{记为}{=}
\widetilde{S}^2
\end{cases}
$$</span> 由于总体的k阶中心矩 <span class="math inline"><em>μ</em><sub><em>k</em></sub> = <em>E</em>(<em>X</em> − <em>E</em><em>X</em>)<sup><em>k</em></sup></span>
总可以通过展开的方法化为阶数不超过 <span class="math inline"><em>k</em></span> 的总体原点矩的函数，而样本的 <span class="math inline"><em>k</em></span> 阶中心矩 <span class="math inline">$B_k = \frac{1}{n} \sum_{i = 1}^{n} (X_i -
\overline{X})^k$</span> 同样也可展开为阶数不超过 <span class="math inline"><em>k</em></span> 的样本原点矩的函数</p>
<p>上述推导得出两个核心结论： 1. <strong>总体均值 <span class="math inline"><em>μ</em></span> 的矩估计</strong> <span class="math display">$$
   \hat{\mu} = \overline{X} = \frac{1}{n}\sum_{i=1}^n X_i
   $$</span> 直接用样本均值估计总体均值</p>
<ol start="2" type="1">
<li><p><strong>总体方差 <span class="math inline"><em>σ</em><sup>2</sup></span> 的矩估计</strong>
<span class="math display">$$
\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^n (X_i - \overline{X})^2
\triangleq \widetilde{S}^2
$$</span>
用样本二阶中心矩估计总体方差，注意这是有偏估计，（真实方差需用无偏估计
<span class="math inline">$S^2 = \frac{1}{n-1}\sum (X_i -
\overline{X})^2$</span>）。</p>
<p>但是当样本量 <span class="math inline"><em>n</em> → ∞</span>
时，<span class="math inline"><em>S̃</em><sup>2</sup></span>
会趋近真实方差。</p></li>
</ol>
<p>因此上述例子的结论可作为矩估计法推广到一般情形，即可以用样本的 k
阶中心矩作为总体的 k
阶中心矩的矩估计量。此结论很有用，在实际中很方便。</p>
<h4 id="均匀分布的矩估计">均匀分布的矩估计</h4>
<p>设总体 <span class="math inline"><em>X</em></span> 服从 <span class="math inline">[<em>a</em>, <em>b</em>]</span> 上的均匀分布， <span class="math inline"><em>a</em>, <em>b</em></span> 为待估参数，<span class="math inline">(<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, ⋯, <em>X</em><sub><em>n</em></sub>)</span>
为取自 <span class="math inline"><em>X</em></span> 的样本，求 <span class="math inline"><em>a</em>, <em>b</em></span> 的矩估计量 。</p>
<p>利用矩估计法原理：需列出总体一、二阶中心矩等于样本一、二阶中心矩的方程。</p>
<p>已知均匀分布 $XU[a,b] $ 的期望 $EX = $，方差 <span class="math inline">$DX=\frac{1}{12}(b - a)^2$</span> （方差是二阶中心矩
）。</p>
<p>样本一阶中心矩对应样本均值 $=_{i = 1}^{n}X_i $</p>
<p>样本二阶中心矩为 $^2=_{i = 1}^{n}(X_i - )^2 $。</p>
<ul>
<li><p>联立矩方程：
令总体一阶原点矩（期望）等于样本一阶原点矩（样本均值），总体二阶中心矩（方差）等于样本二阶中心矩，得到方程组：
<span class="math display">$$
\begin{cases}
\frac{1}{2}(a + b)=\overline{X} \\
\frac{1}{12}(b - a)^2=\frac{1}{n}\sum_{i = 1}^{n}(X_i -
\overline{X})^2=\widetilde{S}^2
\end{cases}
$$</span></p></li>
<li><p>通过解上述方程组，得到待估参数 $ a,b $ 的矩估计量 <span class="math display">$$
\hat{a}=\overline{X}-\sqrt{3}\widetilde{S}, \quad
\hat{b}=\overline{X}+\sqrt{3}\widetilde{S}
$$</span> 其中 $ =$ ，是样本二阶中心矩的开方形式 。</p></li>
</ul>
<h2 id="最大似然估计法">最大似然估计法</h2>
<h3 id="什么是最大似然估计法">什么是最大似然估计法</h3>
<p>最大似然估计（极大似然估计），是另一种点估计方法，也是机器学习等学科中经常使用到的方法。简直就是重中之重。</p>
<p>简单来说，就是使样本事件发生概率最大的参数值，作为总体参数的估计值，就是<strong>极大似然估计</strong>。</p>
<p>怎么理解呢？举个例子。</p>
<p>比如箱子中有100个球，共两种颜色白和黑。已知白球和黑球的比例是1:99（但不知道谁是1）。目标是估计箱子中什么颜色是99个。随机抽取一个球，发现是白球。那么从直观上讲，是不是大概率箱子中是99个白球？当然也有可能箱子中是99个黑球，正好有1个白球还正好被抽到了。但是明显这种情况概率较小。</p>
<p>上面这个例子，就是极大似然估计的过程。选择的是概率最大的参数。</p>
<p>极大似然估计的应用过程如下，也比较简单，通常遵循以下步骤</p>
<ul>
<li><p><strong>写出总体的概率/密度函数</strong></p>
<p>当总体是离散型变量时，写的是概率函数；当总体是连续型函数时，写的是密度函数</p></li>
<li><p><strong>写出似然函数</strong></p>
<p>构造似然函数如下： <span class="math display">$$
L(\theta) = L(x_1, x_2, \cdots, x_n ; \theta) = \prod_{i = 1}^{n} f(x_i
; \theta)
$$</span>
从上面的公式中，其实就是将每个样本观测值带入总体概率函数中，求所有样本的概率连乘。这个连乘，就是关于总体参数的一个似然函数。</p>
<p>似然函数有了，下面，我们的目标就是求使得该函数取最大值时的参数值，这个参数值就将作为一个总体参数的极大似然估计。</p></li>
<li><p><strong>两边取<span class="math inline"><em>l</em><em>n</em></span></strong></p>
<p>由于通常似然函数都是连乘的形式，不容易取到最值，因此采用取<span class="math inline"><em>l</em><em>n</em></span>的方式，将连乘变形为加法。</p></li>
<li><p><strong>两边求导，令导数=0，求参数</strong></p>
<p>通常情况下，最值都是在导数为0的地方取到，这里令导数=0，求参数。即此时的参数值，使得导数为0，取得整体似然函数的最大值。即，此时的参数值是整体参数的极大似然估计。</p>
<p>当然，如果是多个参数的情况下，这里则分别对每个参数求偏导数，令偏导数为0，分别求各个参数的极大似然估计。</p></li>
</ul>
<h3 id="具体求法-1">具体求法</h3>
<p>设总体X的概率密度为<span class="math inline"><em>f</em>(<em>x</em>; <em>θ</em>)</span>（当<span class="math inline"><em>X</em></span>为离散型时，<span class="math inline"><em>f</em>(<em>x</em>; <em>θ</em>)</span>为概率），<span class="math inline"><em>θ</em> = (<em>θ</em><sub>1</sub>, <em>θ</em><sub>2</sub>, ⋯, <em>θ</em><sub><em>k</em></sub>)</span>为待估的未知参数，<span class="math inline">(<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, ⋯, <em>x</em><sub><em>n</em></sub>)</span>为样本<span class="math inline">(<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, ⋯, <em>X</em><sub><em>n</em></sub>)</span>的一组观测值，称
<span class="math display">$$
L(\theta) = L(x_1, x_2, \cdots, x_n ; \theta) = \prod_{i = 1}^{n} f(x_i
; \theta)
$$</span> 为样本的似然函数，若存在某个<span class="math inline"><em>θ̂</em> = (<em>θ̂</em><sub>1</sub>, <em>θ̂</em><sub>2</sub>, ⋯, <em>θ̂</em><sub><em>k</em></sub>)</span>，使得
<span class="math display"><em>L</em>(<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, ⋯, <em>x</em><sub><em>n</em></sub>; <em>θ̂</em>) = max<sub><em>θ</em> ∈ <em>Θ</em></sub><em>L</em>(<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, ⋯, <em>x</em><sub><em>n</em></sub>; <em>θ</em>)</span>
成立（其中 <span class="math inline"><em>Θ</em></span> 为 <span class="math inline"><em>θ</em></span> 的所有可能取值范围），则称 <span class="math display">$$
\begin{align*}
\hat{\theta} &amp;= \hat{\theta}(x_1, x_2, \cdots, x_n) \\
&amp;= \big( \hat{\theta}_1(x_1, \cdots, x_n), \cdots,
\hat{\theta}_k(x_1, \cdots, x_n) \big)
\end{align*}
$$</span> 为<span class="math inline"><em>θ</em></span>的最大似然估计值，而称 <span class="math display">$$
\begin{align*}
\hat{\theta} &amp;= \hat{\theta}(X_1, X_2, \cdots, X_n) \\
&amp;= \big( \hat{\theta}_1(X_1, \cdots, X_n), \cdots,
\hat{\theta}_k(X_1, \cdots, X_n) \big)
\end{align*}
$$</span> 为<span class="math inline"><em>θ</em></span>的最大似然估计量。</p>
<p>由定义知，求总体参数 <span class="math inline"><em>θ</em></span>
的最大似然估计 <span class="math inline"><em>θ̂</em></span>
的问题，就是求似然函数 $L() $
的最大值问题。当然，该最大值问题解的存在性也值得关注。由微积分学知，若似然函数<span class="math inline"><em>L</em>(<em>θ</em>)</span>关于<span class="math inline"><em>θ</em></span>（也即关于<span class="math inline"><em>θ</em><sub>1</sub>, <em>θ</em><sub>2</sub>, ⋯, <em>θ</em><sub><em>k</em></sub></span>）有连续偏导数，则最大似然估计<span class="math inline"><em>θ̂</em> = (<em>θ̂</em><sub>1</sub>, <em>θ̂</em><sub>2</sub>, ⋯, <em>θ̂</em><sub><em>k</em></sub>)</span>一般可从方程组：
<span class="math display">$$
\boxed{(7.4) \quad \frac{\partial L(\theta)}{\partial \theta_j} = 0,
\quad j = 1, 2, \cdots, k}
$$</span> 解得.又由于<span class="math inline">ln <em>L</em>(<em>θ</em>)</span>与<span class="math inline"><em>L</em>(<em>θ</em>)</span>同时取得最大值，故等价地可由方程组
<span class="math display">$$
\boxed{(7.5) \quad \frac{\partial \ln L(\theta)}{\partial \theta_j} = 0,
\quad j = 1, 2, \cdots, k}
$$</span></p>
<p>求得<span class="math inline"><em>θ̂</em></span></p>
<p>(7.4)式或(7.5)式称为似然方程.通常，(7.5)式的求解较为简单.于是求解最大似然估计的一般步骤为：</p>
<ul>
<li><p>由总体的分布写出样本的似然函数<span class="math inline"><em>L</em>(<em>θ</em>)</span>；</p></li>
<li><p>建立似然方程(7.4)式或(7.5)式；</p></li>
<li><p>解上述似然方程得参数<span class="math inline"><em>θ</em></span>的最大似然估计<span class="math inline"><em>θ̂</em> = (<em>θ̂</em><sub>1</sub>, <em>θ̂</em><sub>2</sub>, ⋯, <em>θ̂</em><sub><em>k</em></sub>)</span></p></li>
</ul>
<h3 id="例题">例题</h3>
<h4 id="均匀分布的最大似然估计">均匀分布的最大似然估计</h4>
<p>设总体 <span class="math inline"><em>X</em> ∼ <em>U</em>(<em>a</em>, <em>b</em>)</span>（均匀分布），<span class="math inline">(<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X</em><sub><em>n</em></sub>)</span>
为来自该总体的样本。试求参数 <span class="math inline"><em>a</em></span>
和 <span class="math inline"><em>b</em></span>
的最大似然估计（MLE）。</p>
<p>写出概率密度函数</p>
<p>均匀分布的PDF为： <span class="math display">$$
f(x) =
\begin{cases}
\frac{1}{b-a} &amp; \text{若 } a \leq x \leq b \\
0 &amp; \text{其他}
\end{cases}
$$</span> 构建似然函数</p>
<p>对于样本 <span class="math inline">(<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X</em><sub><em>n</em></sub>)</span>，似然函数为：
<span class="math display">$$
L(a, b) = \prod_{i=1}^n f(X_i) =
\begin{cases}
\left(\frac{1}{b-a}\right)^n &amp; \text{若所有 } X_i \in [a, b] \\
0 &amp; \text{否则}
\end{cases}
$$</span></p>
<p>取对数得对数似然函数 <span class="math display">ln <em>L</em>(<em>a</em>, <em>b</em>) = −<em>n</em>ln (<em>b</em> − <em>a</em>)  （仅当
<em>a</em> ≤ <em>X</em><sub><em>i</em></sub> ≤ <em>b</em> 对所有
<em>i</em> 成立时）</span></p>
<p>最大化似然函数</p>
<p>由于 <span class="math inline">ln <em>L</em>(<em>a</em>, <em>b</em>)</span> 关于
<span class="math inline"><em>b</em> − <em>a</em></span>
单调递减，因此需要 <strong>最小化</strong> <span class="math inline"><em>b</em> − <em>a</em></span>，同时满足约束： <span class="math display">$$
\begin{cases}
a \leq \min(X_1, X_2, \dots, X_n), \\
b \geq \max(X_1, X_2, \dots, X_n).
\end{cases}
$$</span> 因此，MLE为： <span class="math display"><em>â</em> = min (<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X</em><sub><em>n</em></sub>),  <em>b̂</em> = max (<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X</em><sub><em>n</em></sub>)</span></p>
<h4 id="一道实际例题">一道实际例题</h4>
<p>某电子管的使用寿命 <span class="math inline"><em>X</em></span>
服从指数分布，其概率密度函数为<br>
<span class="math display">$$
f(x;\theta) =  \begin{cases}  \dfrac{1}{\theta} \mathrm{e}^{-x/\theta},
&amp; x &gt; 0, \theta &gt; 0, \\ 0, &amp; \text{其他}, \end{cases}
$$</span> 今测得一组样本观测值，其具体数据如下（单位：h）：</p>
<p><span class="math inline">16, 29, 50, 68, 100, 130, 140, 270, 280, 340, 410, 450, 520, 620, 190, 210, 800, 1100</span></p>
<p>试求参数 <span class="math inline"><em>θ</em></span>
的最大似然估计.</p>
<p>由题意，似然函数为 <span class="math display">$$
L(x_1, x_2, \cdots, x_n ; \theta) = \prod_{i=1}^{n} \left(
\dfrac{1}{\theta} \mathrm{e}^{-x_i/\theta} \right) = \dfrac{1}{\theta^n}
\exp \left\{ -\dfrac{1}{\theta} \left( \sum_{i=1}^{n} x_i \right)
\right\}
$$</span> 将上式取对数得 <span class="math display">$$
\ln L(x_1, x_2, \cdots, x_n ; \theta) = -n \ln \theta -
\dfrac{1}{\theta} \sum_{i=1}^{n} x_i
$$</span> 对 <span class="math inline"><em>θ</em></span> 求导得似然方程
<span class="math display">$$
-\dfrac{n}{\theta} + \dfrac{1}{\theta^2} \sum_{i=1}^{n} x_i = 0
$$</span> 解方程得 <span class="math inline"><em>θ</em></span>
的最大似然估计值为 <span class="math display">$$
\hat{\theta} = \dfrac{1}{n} \sum_{i=1}^{n} x_i = \bar{x}.
$$</span> 将观测数据代入 <span class="math inline"><em>θ̂</em></span>
中，得 <span class="math inline"><em>θ</em></span> 的最大似然估计值为
<span class="math display">$$
\begin{align*} \hat{\theta} &amp;= \bar{x} = \dfrac{1}{n} \sum_{i=1}^{n}
x_i \\ &amp;= \dfrac{1}{18} (16 + 29 + \cdots + 800 + 1100) = 318 \,
(\text{h}). \end{align*}
$$</span> 答，参数 <span class="math inline"><em>θ</em></span>
的最大似然估计的估计值为 318</p>
<h4 id="双参指数分布的最大似然估计">双参指数分布的最大似然估计</h4>
<p>设总体 <span class="math inline"><em>X</em></span> 的概率密度函数为：
<span class="math display">$$
f(x; \theta, \lambda) = \begin{cases}
\lambda e^{-\lambda(x-\theta)}, &amp; x \geq \theta \\
0, &amp; x &lt; \theta
\end{cases}
$$</span> 其中 <span class="math inline"><em>θ</em> ∈ ℝ</span> 和 <span class="math inline"><em>λ</em> &gt; 0</span> 是未知参数。给定样本 <span class="math inline"><em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X</em><sub><em>n</em></sub></span>，求
<span class="math inline"><em>θ</em></span> 和 <span class="math inline"><em>λ</em></span> 的最大似然估计量 <span class="math inline"><em>θ̂</em><sub>MLE</sub></span> 和 <span class="math inline"><em>λ̂</em><sub>MLE</sub></span>。</p>
<p>解题步骤</p>
<p>构造似然函数</p>
<p>由于样本独立同分布，似然函数为： <span class="math display">$$
L(\theta, \lambda; x_1, x_2, \dots, x_n) = \prod_{i=1}^n \lambda
e^{-\lambda(x_i - \theta)} \cdot I(x_i \geq \theta)
$$</span> 其中 <span class="math inline"><em>I</em>(⋅)</span>
是示性函数，确保所有样本点 <span class="math inline"><em>x</em><sub><em>i</em></sub> ≥ <em>θ</em></span>。</p>
<p>当所有 <span class="math inline"><em>x</em><sub><em>i</em></sub> ≥ <em>θ</em></span>
时，似然函数可简化为： <span class="math display">$$
L(\theta, \lambda) = \lambda^n e^{-\lambda \sum_{i=1}^n (x_i - \theta)}
= \lambda^n e^{-\lambda \left(\sum_{i=1}^n x_i - n\theta\right)}
$$</span></p>
<p>取 <span class="math inline"><em>l</em><em>n</em></span> <span class="math display">$$
\ln L(\theta, \lambda) = n \ln \lambda - \lambda \left(\sum_{i=1}^n x_i
- n\theta\right)
$$</span> 注意：对数似然函数仅在 <span class="math inline"><em>θ</em> ≤ min (<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, …, <em>x</em><sub><em>n</em></sub>)</span>
时有定义。</p>
<p>最大化关于 <span class="math inline"><em>θ</em></span> 的对数似然</p>
<p><span class="math inline">ln <em>L</em></span> 中与 <span class="math inline"><em>θ</em></span> 相关的项为 <span class="math inline"><em>n</em><em>λ</em><em>θ</em></span>，且 <span class="math inline"><em>λ</em> &gt; 0</span>。为使 <span class="math inline">ln <em>L</em></span> 最大，需让 <span class="math inline"><em>θ</em></span> 尽可能大，但必须满足 <span class="math inline"><em>θ</em> ≤ min (<em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, …, <em>x</em><sub><em>n</em></sub>)</span>。</p>
<p>因此，<span class="math inline"><em>θ</em></span> 的最大似然估计为：
<span class="math display"><em>θ̂</em><sub>MLE</sub> = min (<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, …, <em>X</em><sub><em>n</em></sub>)</span></p>
<p>最大化关于 <span class="math inline"><em>λ</em></span> 的对数似然</p>
<p>固定 <span class="math inline"><em>θ</em> = <em>θ̂</em><sub>MLE</sub></span>，对
<span class="math inline">ln <em>L</em></span> 求导并令导数为零： <span class="math display">$$
\frac{\partial \ln L}{\partial \lambda} = \frac{n}{\lambda} -
\left(\sum_{i=1}^n x_i - n\theta\right) = 0
$$</span> 解得： <span class="math display">$$
\lambda = \frac{n}{\sum_{i=1}^n x_i - n\theta}
$$</span> 代入 <span class="math inline"><em>θ̂</em><sub>MLE</sub></span>，得到： <span class="math display">$$
\hat{\lambda}_{\text{MLE}} = \frac{n}{\sum_{i=1}^n X_i - n \cdot
\min(X_1, X_2, \dots, X_n)}
$$</span></p>
<p>最终答案 参数 <span class="math inline"><em>θ</em></span> 和 <span class="math inline"><em>λ</em></span> 的最大似然估计分别为： <span class="math display">$$
\boxed{\hat{\theta}_{\text{MLE}} = \min(X_1, X_2, \dots, X_n)}
$$</span> <span class="math display">$$
\boxed{\hat{\lambda}_{\text{MLE}} = \frac{n}{\sum_{i=1}^n X_i - n \cdot
\min(X_1, X_2, \dots, X_n)}}
$$</span></p>
<h2 id="估计量的评选原则">估计量的评选原则</h2>
<h3 id="无偏性">无偏性</h3>
<h4 id="如何理解无偏性">如何理解无偏性</h4>
<p>点估计方法判断一个点是好还是坏，涉及到的其中原则之一就是无偏性。</p>
<p>无偏性的含义是：<strong>用样本估计的参数值的期望，等于真实值。</strong></p>
<p>通俗简单来讲，意思就是，用这个估计方法 <strong>“猜”
参数的值时，既不会系统性地高估，也不会系统性地低估，长期来看是准确的。</strong></p>
<ul>
<li><strong>例子</strong>：假设你有一个电子秤，每次称同一块巧克力的重量时：
<ul>
<li><strong>无偏的秤</strong>：有时称得重一点，有时轻一点，但
<strong>长期平均</strong> 刚好是真实重量。</li>
<li><strong>有偏的秤</strong>：总是比真实重量多 5
克（系统性地高估）。</li>
</ul></li>
</ul>
<p>这个其实很好理解。我们进行参数估计不就是为了尽可能“猜”出总体参数的数值嘛，如果连期望都不相等，那岂不是基本就估计错了么……</p>
<p>在统计学中，<strong>“无偏估计量”</strong>
就像那个无偏的秤——用它估计参数时，虽然单次结果可能有误差，但
<strong>反复多次估计后的平均值会等于真实参数值</strong>。所以无偏估计量长期来看是准确的，避免系统性误差。</p>
<p><strong>样本均值 vs 总体均值</strong></p>
<ul>
<li>用样本均值 <span class="math inline">$\bar{X} = \frac{1}{n}\sum
X_i$</span> 估计总体均值 <span class="math inline"><em>μ</em></span>
时，<span class="math inline"><em>X̄</em></span> 是无偏的，因为 <span class="math inline"><em>E</em>(<em>X̄</em>) = <em>μ</em></span>。</li>
<li>推断：从总体中随机抽样，样本均值会围绕真实均值波动，但不会系统性偏离。</li>
</ul>
<p><strong>样本方差的有偏与无偏版本</strong></p>
<ul>
<li><strong>有偏估计</strong>：<span class="math inline">$\widetilde{S}^2 = \frac{1}{n}\sum (X_i -
\bar{X})^2$</span>，它的期望 <span class="math inline">$E(\widetilde{S}^2) = \frac{n-1}{n} \sigma^2 &lt;
\sigma^2$</span>（低估方差）。</li>
<li><strong>无偏估计</strong>：<span class="math inline">$S^2 =
\frac{1}{n-1}\sum (X_i - \bar{X})^2$</span>，修正后 <span class="math inline"><em>E</em>(<em>S</em><sup>2</sup>) = <em>σ</em><sup>2</sup></span>。</li>
<li><strong>推断</strong>：因为 <span class="math inline"><em>X̄</em></span> 本身是用样本数据算的，导致 <span class="math inline"><em>S̃</em><sup>2</sup></span> 低估真实方差，需要除以
<span class="math inline"><em>n</em> − 1</span> 而不是 <span class="math inline"><em>n</em></span> 来修正。</li>
</ul>
<h4 id="无偏性的定义">无偏性的定义</h4>
<p>定义 7.2 设 <span class="math inline"><em>θ̂</em> = <em>θ̂</em>(<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, ⋯, <em>X</em><sub><em>n</em></sub>)</span>
是参数 <span class="math inline"><em>θ</em></span> 的估计量，若对任意
<span class="math inline"><em>θ</em> ∈ <em>Θ</em></span>，有 <span class="math display"><em>E</em><em>θ̂</em> = <em>θ</em></span> 则称 <span class="math inline"><em>θ̂</em></span> 是 <span class="math inline"><em>θ</em></span> 的无偏估计量（或称估计量 <span class="math inline"><em>θ̂</em></span> 是无偏的）。记 <span class="math display"><em>b</em><sub><em>n</em></sub> = <em>E</em><em>θ̂</em> − <em>θ</em></span>
称 <span class="math inline"><em>b</em><sub><em>n</em></sub></span>
为估计量 <span class="math inline"><em>θ̂</em></span> 的偏差，当 <span class="math inline"><em>b</em><sub><em>n</em></sub> ≠ 0</span> 时，称
<span class="math inline"><em>θ̂</em></span> 是 <span class="math inline"><em>θ</em></span> 的有偏估计。若 <span class="math display">lim<sub><em>n</em> → ∞</sub><em>b</em><sub><em>n</em></sub> = 0</span>
则称 <span class="math inline"><em>θ̂</em></span> 是 <span class="math inline"><em>θ</em></span> 的渐近无偏估计。</p>
<h4 id="如何证明无偏性来俩例题">如何证明无偏性，来俩例题</h4>
<h5 id="证明样本均值overline-x总是总体均值ex的无偏估计量">证明样本均值<span class="math inline">$\overline X$</span>总是总体均值<span class="math inline"><em>E</em><em>X</em></span>的无偏估计量</h5>
<p>设总体 $ X $ 的 $ k $ 阶矩 $ a_k = E(X^k) <span class="math inline">（</span> k <span class="math inline">）<em>存</em><em>在</em>，</span> (X_1, X_2, , X_n)
$ 是 $ X $ 的样本。试证明样本 $ k $ 阶矩 $ A_k = _{i = 1}^n X_i^k $ 是 $
a_k $ 的无偏估计。</p>
<p>由样本的定义知 ( X_1, X_2, , X_n ) 与 ( X ) 同分布，因此<br>
<span class="math display"><em>E</em>(<em>X</em><sub><em>i</em></sub><sup><em>k</em></sup>) = <em>E</em>(<em>X</em><sup><em>k</em></sup>) = <em>a</em><sub><em>k</em></sub>, <em>k</em> ≥ 1,  <em>i</em> = 1, 2, ⋯, <em>n</em></span>
故 <span class="math display">$$
EA_k = \frac{1}{n} \sum_{i = 1}^n E(X_i^k) = a_k
$$</span></p>
<h5 id="证明s2-frac1n-1sum-x_i---barx2是sigma-2的无偏估计量">证明<span class="math inline">$S^2 = \frac{1}{n-1}\sum (X_i -
\bar{X})^2$</span>是<span class="math inline"><em>σ</em><sup>2</sup></span>的无偏估计量</h5>
<p>设总体方差 $ DX = ^2 &lt; $，试证样本方差 $ S^2 = _{i = 1}^n (X_i -
{X})^2 $ 是 $ ^2 $ 的无偏估计量。</p>
<p>设总体均值 $ EX = $，由于 $ DX = ^2 &lt; $，故 $ $ 存在且有限。 <span class="math display">$$
\begin{align*}
ES^2 &amp;= E\left[ \frac{1}{n - 1} \sum_{i = 1}^n (X_i - \bar{X})^2
\right] \\
&amp;= E\left\{ \frac{1}{n - 1} \sum_{i = 1}^n \left[ (X_i - \mu) -
(\bar{X} - \mu) \right]^2 \right\} \\
&amp;= \frac{1}{n - 1} E\left\{ \sum_{i = 1}^n \left[ (X_i - \mu)^2 -
2(X_i - \mu)(\bar{X} - \mu) + (\bar{X} - \mu)^2 \right] \right\} \\
&amp;= \frac{1}{n - 1} \left[ \sum_{i = 1}^n E(X_i - \mu)^2 - 2E \sum_{i
= 1}^n (X_i - \mu)(\bar{X} - \mu) + nE(\bar{X} - \mu)^2 \right] \\
&amp;= \frac{1}{n - 1} \sum_{i = 1}^n E(X_i - \mu)^2 - \frac{2}{n - 1} E
\sum_{i = 1}^n (X_i - \mu)(\bar{X} - \mu) + \frac{n}{n - 1} E(\bar{X} -
\mu)^2 \\
&amp;= \frac{n}{n - 1} \sigma^2 - \frac{n}{n - 1} \cdot
\frac{\sigma^2}{n} \\
&amp;= \sigma^2.
\end{align*}
$$</span> 即样本方差是总体方差的无偏估计量。</p>
<p>我们知道，总体方差 $ ^2 $ 的矩估计 $ ^2 = _{i = 1}^n (X_i - {X})^2 $
是有偏估计，这是因为 <span class="math display">$$
E\widetilde{S}^2 = E\left( \frac{n - 1}{n} S^2 \right) = \frac{n - 1}{n}
ES^2 = \frac{n - 1}{n} \sigma^2
$$</span> 可见 $ ^2 $ 为 $ ^2 $ 的渐近无偏估计，故当 <span class="math inline"><em>n</em></span> 比较大时，取 $ S^2 $ 和 $ ^2 $
作为 $ ^2 $ 的估计皆可。</p>
<p>显然，对于同一未知参数，可以构造许多无偏估计。例如，若 $ (X_1, X_2, ,
X_n) $ 是总体 $ X $ 的一个样本，$ c_i <span class="math inline">（</span> 1 i n $）是满足 $ _{i = 1}^n c_i = 1 $
的任意常数，则估计量 <span class="math display">$$
\sum_{i = 1}^n c_i X_i
$$</span> 都是总体期望 <span class="math inline"><em>E</em><em>X</em></span> 的无偏估计。</p>
<h3 id="有效性">有效性</h3>
<h4 id="如何理解有效性">如何理解有效性</h4>
<p>其实可以这么理解，<strong>有效性</strong> 衡量的是
<strong>估计量的“精度”</strong>：</p>
<ul>
<li>如果两个估计量都是无偏的（长期来看都猜得准），但其中一个的估计结果
<strong>波动更小、更稳定</strong>，我们就说它
<strong>更有效</strong>。</li>
<li><strong>类比</strong>：
<ul>
<li>无偏但 <strong>低效</strong> 的估计量 →
一个总是瞄准靶心但手抖的弓箭手（箭落点分散）。</li>
<li>无偏且 <strong>高效</strong> 的估计量 →
一个既瞄准靶心又手稳的弓箭手（箭密集命中靶心）。</li>
</ul></li>
</ul>
<figure>
<img src="/posts/5644/image-20250625205230364.png" alt="image-20250625205230364">
<figcaption aria-hidden="true">image-20250625205230364</figcaption>
</figure>
<p>所以有效性的含义是：用样本估计的参数值的方差，如果越小，就越有效。</p>
<p>两个估计都是无偏的，但是第二个估计明显更集中，方差更小，因此效果也就更好。因为更加容易和真实值（即总体参数）相近。</p>
<h4 id="有效性的定义">有效性的定义</h4>
<p>设 <span class="math inline">$\hat{\theta_1}=\hat{\theta_1}\left(X_{1}, X_{2},
\cdots, X_{n}\right)$</span> 和 <span class="math inline">$\hat{\theta_2}=\hat{\theta_2}\left(X_{1}, X_{2},
\cdots, X_{n}\right)$</span> 都是待估计参数参数 <span class="math inline"><em>θ</em></span> 的两个
<strong>无偏估计量</strong>，若： <span class="math display"><em>D</em>(<em>θ̂</em><sub>1</sub>) &lt; <em>D</em>(<em>θ̂</em><sub>2</sub>)</span>
则称 <span class="math inline"><em>θ̂</em><sub>1</sub></span> 比 <span class="math inline"><em>θ̂</em><sub>2</sub></span>
<strong>更有效</strong>。</p>
<ul>
<li><p>在无偏估计中，方差越小越好</p></li>
<li><p><strong>方差越小</strong> → 估计量的波动越小 →
更可能接近真实值。</p></li>
</ul>
<h4 id="有效性证明的例题">有效性证明的例题</h4>
<p>例题1：设总体服从区间 <span class="math inline">[0, <em>θ</em>]</span> 上的均匀分布，<span class="math inline">(<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, ⋯, <em>X</em><sub><em>n</em></sub>)</span>
为取自该总体的容量为 <span class="math inline"><em>n</em></span>
的样本，对未知参数 <span class="math inline"><em>θ</em></span>
的两个估计量： <span class="math display">$$
\hat{\theta}_1 = 2\bar{X}, \quad \hat{\theta}_2 = \frac{n + 1}{n}
\max_{1 \leq i \leq n} \{X_i\}.
$$</span></p>
<ul>
<li><p>试验证 <span class="math inline"><em>θ̂</em><sub>1</sub></span> 和
<span class="math inline"><em>θ̂</em><sub>2</sub></span> 均为 <span class="math inline"><em>θ</em></span> 的无偏估计；</p></li>
<li><p>指出哪一个更有效。</p></li>
</ul>
<p>解答： <span class="math display">$$
E(\hat{\theta}_1) = 2E(\bar{X}) = 2 \times \frac{\theta}{2} = \theta
$$</span></p>
<p><span class="math display">$$
E(X_{(n)}) = \int_0^\theta x \cdot \frac{n x^{n - 1}}{\theta^n} \, dx =
\frac{n}{n + 1} \theta
$$</span></p>
<p><span class="math display">$$
E(\hat{\theta}_2) = \frac{n + 1}{n} E(X_{(n)}) = \theta
$$</span></p>
<p>故 <span class="math inline"><em>θ̂</em><sub>1</sub></span> 和 <span class="math inline"><em>θ̂</em><sub>2</sub></span> 均为 <span class="math inline"><em>θ</em></span> 的无偏估计. <span class="math display">$$
D(\hat{\theta}_1) = 4D(\bar{X}) = \frac{4}{n^2} \sum_{i = 1}^n D(X_i) =
\frac{4}{n^2} \times n \cdot \frac{\theta^2}{12} = \frac{\theta^2}{3n}
$$</span></p>
<p><span class="math display">$$
E(X_{(n)}^2) = \int_0^\theta x^2 \cdot \frac{n x^{n - 1}}{\theta^n} \,
dx = \frac{n}{n + 2} \theta^2
$$</span></p>
<p><span class="math display">$$
\begin{align*}
D(X_{(n)}) &amp;= E(X_{(n)}^2) - E^2(X_{(n)}) \\
&amp;= \frac{n}{n + 2} \theta^2 - \left( \frac{n}{n + 1} \theta
\right)^2 \\
&amp;= \frac{n}{(n + 2)(n + 1)^2} \theta^2,
\end{align*}
$$</span></p>
<p><span class="math display">$$
D(\hat{\theta}_2) = \left( \frac{n + 1}{n} \right)^2 D(X_{(n)}) =
\frac{\theta^2}{(n + 2)n}
$$</span></p>
<p>显然当 <span class="math inline"><em>n</em> &gt; 1</span> 时，<span class="math inline">$\frac{1}{n(n + 2)} &lt; \frac{1}{3n}$</span>，故
<span class="math inline"><em>θ̂</em><sub>2</sub></span> 比 <span class="math inline"><em>θ̂</em><sub>1</sub></span> 有效</p>
<p>例题2：设总体 <span class="math inline"><em>X</em> ∼ <em>B</em>(1, <em>p</em>)</span>
有容量为 <span class="math inline"><em>n</em></span> 的样本 <span class="math inline">(<em>X</em><sub>1</sub>, <em>X</em><sub>2</sub>, ⋯, <em>X</em><sub><em>n</em></sub>)</span>，其中
<span class="math inline"><em>p</em> ∈ (0, 1)</span> 未知. 求 <span class="math inline"><em>p</em></span> 的无偏估计量的方差下界.</p>
<p>由 <span class="math inline"><em>X</em></span> 的概率分布列 <span class="math display"><em>f</em>(<em>x</em>; <em>p</em>) = <em>p</em><sup><em>x</em></sup>(1 − <em>p</em>)<sup>1 − <em>x</em></sup>,  <em>x</em> = 0, 1</span>
有 <span class="math display">$$
\frac{\partial}{\partial p} \ln f(x; p) = \frac{\partial}{\partial p}
\left[ x \ln p + (1 - x) \ln (1 - p) \right] = \frac{x}{p} - \frac{1 -
x}{1 - p} = \frac{x - p}{p(1 - p)}
$$</span> 从而 <span class="math display">$$
\begin{align*}
I(p) &amp;= E\left( \frac{X - p}{p(1 - p)} \right)^2 \\
&amp;= \frac{1}{p^2(1 - p)^2} E(X - p)^2 \\
&amp;= \frac{1}{p^2(1 - p)^2} D(X) \\
&amp;= \frac{1}{p(1 - p)},
\end{align*}
$$</span> 此即，<span class="math inline"><em>p</em></span>
的无偏估计量方差下界为 <span class="math inline">$\frac{p(1 -
p)}{n}$</span></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/ergou10086">ErgouTree</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://ergou10086.github.io/posts/5644.html">https://ergou10086.github.io/posts/5644.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://ergou10086.github.io" target="_blank">ErgouTree's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E7%B1%BB/">学习类</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6/">数学</a><a class="post-meta__tags" href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/">概率论与数理统计</a></div><div class="post-share"><div class="addtoany"><div class="a2a_kit a2a_kit_size_32 a2a_default_style"><a class="a2a_button_facebook"></a><a class="a2a_button_twitter"></a><a class="a2a_button_wechat"></a><a class="a2a_button_sina_weibo"></a><a class="a2a_button_facebook_messenger"></a><a class="a2a_button_email"></a><a class="a2a_button_copy_link"></a><a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a></div></div><script async="async" src="https://static.addtoany.com/menu/page.js"></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/posts/19945.html" title="大数定律部分定理详解"><img class="cover" src="/images/posts/cover_Tijie.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">大数定律部分定理详解</div></div><div class="info-2"><div class="info-item-1">切比雪夫不等式 定理内容 设随机变量X的期望和方差均存在，则对任意ε &gt; 0，有 $$ P(\vert X - EX\vert\geq\varepsilon)\leq\frac{DX}{\varepsilon^{2}} $$ 等价形式为 $$ P(\vert X - EX\vert&lt;\varepsilon)\geq1 - \frac{DX}{\varepsilon^{2}} $$ 定理内容解释 切比雪夫不等式告诉我们主要就一件事，对于一个随机变量 X，，如果它的平均值（期望 EX）和波动程度（方差 DX）都知道，那么 X 的值偏离平均值太远的概率是有限的。  表示即使分布未知，随机变量的取值落在期望左右的一定范围内的概率是有界的，该界限和方差有关。DX 越小，落在某范围内的概率就越大，表示 X 取值的概率分布越集中。也就是说，方差 DX 可以表示随机变量 X 取值的离散程度。 描述了任意随机变量的取值偏离其期望值的概率上限，不依赖于具体分布，仅需要方差存在.  具体来说：  偏离的概率：X...</div></div></div></a><a class="pagination-related" href="/posts/9946.html" title="参数估计之区间估计"><img class="cover" src="/images/posts/cover_math4.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">参数估计之区间估计</div></div><div class="info-2"><div class="info-item-1">区间估计 什么是区间估计 上一篇文章中我们理解了什么是点估计，这次就是参数估计的另一种估计方式，区间估计。 由于点估计忽略了抽样波动性，为了更全面地反映参数估计的可靠性，我们引入区间估计 和理解点估计一样，区间估计就是估计未知参数θ的可能取值范围和这个范围包含该未知参数θ的可信程度，这个范围就是区间估计的估计内容 区间估计不仅给出一个中心点，还给出了一个上下界，使得该区间在一定的置信水平下包含真实参数值。例如，当我们计算出某总体均值的95%置信区间为[a, b]时，可以理解为在相同抽样条件下重复实验，约有95%的构造出的区间会包含总体均值。 具体说，区间估计是统计学中用来估计未知参数（比如均值、比例等）的一种方法。它不像点估计那样只给出一个具体的数值（比如“平均身高是170cm”），而是给出一个范围（比如“平均身高在168cm到172cm之间”），并说明这个范围的可信程度（比如“有95%的把握”）。 构造步骤 以单个正态总体均值的区间估计为例，构造置信区间通常包括以下步骤：  若总体服从正态分布，则样本均值 $\overline...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/posts/50276.html" title="一些分布函数的数字特征的求解过程"><img class="cover" src="/images/posts/cover_wish.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-26</div><div class="info-item-2">一些分布函数的数字特征的求解过程</div></div><div class="info-2"><div class="info-item-1">前言 在这里主要是进行求一些常见分布的一些数字特性，包括期望，方差等 主要写的是计算过程，这些分布的数字特征是怎么计算来的，我个人喜欢把计算过程写的比较详细，感觉多的大概扫一眼就知道这东西其实都是怎么求的了 两点分布 重复一下分布表示 设随机变量 X 服从参数为 p 的两点分布（也称为伯努利分布），其概率质量函数为： P(X = 1) = p,  P(X = 0) = 1 − p 其中 0 ≤ p ≤ 1。 期望（数学期望） 期望 E[X] 的计算公式为： E[X] = ∑xx ⋅ P(X = x) = 0 ⋅ P(X = 0) + 1 ⋅ P(X = 1) 代入概率质量函数： E[X] = 0 ⋅ (1 − p) + 1 ⋅ p = p 因此，两点分布的期望为： E[X] = p 方差 方差 D(X) 的计算公式为： D(X) = E[X2] − (E[X])2 计算 E[X2]...</div></div></div></a><a class="pagination-related" href="/posts/48358.html" title="关于常用六大分布的一些内容"><img class="cover" src="/images/posts/cover2x.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-23</div><div class="info-item-2">关于常用六大分布的一些内容</div></div><div class="info-2"><div class="info-item-1">哪六大分布 离散型分布  两点分布 X ∼ B(1, p) 二项分布 X ∼ B(n, p) 泊松分布 X ∼ P(λ)  连续型分布  均匀分布 X ∼ U(a, b) 指数分布 X ∼ E(λ) 正态分布 X ∼ N(μ, σ2)  之后搞一个每个分布都单开一个文章把里面所有需要搞的东西，全搞了 一些公式备忘 期望公式 离散型随机变量的期望 若随机变量 X 取值为 x1, x2, …, xn，对应概率为 P(X = xi) = pi，则期望为 $$ E(X) = \sum_{i=1}^{n} x_i \cdot p_i $$ 连续型随机变量的期望 若随机变量 X 的概率密度函数为 f(x)，则期望为： E(X) = ∫−∞+∞x ⋅ f(x) dx 方差公式 基于期望的定义式 随机变量 X 的方差表示为D(X)，定义为： D(X) = E[(X − E(X))2] 展开计算式 D(X) = E(X2) − [E(X)]2 离散型随机变量的方差 $$ D(X) = \sum_{i=1}^{n} (x_i -...</div></div></div></a><a class="pagination-related" href="/posts/20606.html" title="无偏估计性与估计有效程度比较的例题解析"><img class="cover" src="/images/posts/cover_theory2.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-05-17</div><div class="info-item-2">无偏估计性与估计有效程度比较的例题解析</div></div><div class="info-2"><div class="info-item-1"> 问题重述 我们需要证明样本方差 $S^2 = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \overline{X})^2$ 是总体方差 σ2 = D(X) 的无偏估计量。即证明 E[S2] = σ2。 证明步骤  设定和已知条件：  总体 X 的均值 E(X) = μ，方差 D(X) = σ2 &lt; ∞。 样本 X1, X2, …, Xn 是独立同分布（i.i.d.）的，与 X 同分布。 样本均值 $\overline{X} = \frac{1}{n} \sum_{i=1}^{n} X_i$。  展开样本方差： $$ S^2 = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \overline{X})^2 $$ 我们首先将 $(X_i - \overline{X})$ 表示为 $(X_i - \mu) - (\overline{X} - \mu)$： $$ (X_i - \overline{X}) = (X_i - \mu) - (\overline{X} -...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/arp.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">ErgouTree</div><div class="author-info-description">I start a brand-new life with you.</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">148</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">82</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">55</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ergou10086"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/ergou10086" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="/zjm88822201@126.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="https://space.bilibili.com/142045656?spm_id_from=333.1007.0.0" target="_blank" title="bilibili"><i class="fas fa-brands fa-bilibili" style="color: #4a72be;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">作者长期陷入galgame和osu!maina4k中 祝他好运吧 对了 如果图片加载过慢 建议科学上网进行使用</div></div><div class="card-widget"><div class="item-headline"><i></i><span></span></div><div class="item-content"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1%E4%B9%8B%E7%82%B9%E4%BC%B0%E8%AE%A1"><span class="toc-number">1.</span> <span class="toc-text">参数估计之点估计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1"><span class="toc-number">1.1.</span> <span class="toc-text">什么是参数估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E9%87%8F"><span class="toc-number">1.2.</span> <span class="toc-text">估计量</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89"><span class="toc-number">1.2.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%90%86%E8%A7%A3"><span class="toc-number">1.2.2.</span> <span class="toc-text">理解</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E5%80%BC"><span class="toc-number">1.3.</span> <span class="toc-text">估计值</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-1"><span class="toc-number">1.3.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%90%86%E8%A7%A3-1"><span class="toc-number">1.3.2.</span> <span class="toc-text">理解</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%95%E4%B8%BA%E7%82%B9%E4%BC%B0%E8%AE%A1"><span class="toc-number">1.4.</span> <span class="toc-text">何为点估计</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A9%E4%BC%B0%E8%AE%A1%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">矩估计法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%9F%A9%E4%BC%B0%E8%AE%A1%E5%91%A2"><span class="toc-number">2.1.</span> <span class="toc-text">什么是矩估计呢</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E6%B1%82%E6%B3%95"><span class="toc-number">2.2.</span> <span class="toc-text">具体求法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="toc-number">2.3.</span> <span class="toc-text">示例</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B3%8A%E6%9D%BE%E5%88%86%E5%B8%83%E7%9A%84%E7%9F%A9%E4%BC%B0%E8%AE%A1"><span class="toc-number">2.3.1.</span> <span class="toc-text">泊松分布的矩估计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%95%E6%B1%82%E6%80%BB%E4%BD%93%E5%9D%87%E5%80%BC%E5%92%8C%E6%96%B9%E5%B7%AE%E7%9A%84%E7%9F%A9%E4%BC%B0%E8%AE%A1"><span class="toc-number">2.3.2.</span> <span class="toc-text">试求总体均值和方差的矩估计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9D%87%E5%8C%80%E5%88%86%E5%B8%83%E7%9A%84%E7%9F%A9%E4%BC%B0%E8%AE%A1"><span class="toc-number">2.3.3.</span> <span class="toc-text">均匀分布的矩估计</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">最大似然估计法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E6%B3%95"><span class="toc-number">3.1.</span> <span class="toc-text">什么是最大似然估计法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E6%B1%82%E6%B3%95-1"><span class="toc-number">3.2.</span> <span class="toc-text">具体求法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BE%8B%E9%A2%98"><span class="toc-number">3.3.</span> <span class="toc-text">例题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9D%87%E5%8C%80%E5%88%86%E5%B8%83%E7%9A%84%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1"><span class="toc-number">3.3.1.</span> <span class="toc-text">均匀分布的最大似然估计</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E9%81%93%E5%AE%9E%E9%99%85%E4%BE%8B%E9%A2%98"><span class="toc-number">3.3.2.</span> <span class="toc-text">一道实际例题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%8C%E5%8F%82%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83%E7%9A%84%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1"><span class="toc-number">3.3.3.</span> <span class="toc-text">双参指数分布的最大似然估计</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%B0%E8%AE%A1%E9%87%8F%E7%9A%84%E8%AF%84%E9%80%89%E5%8E%9F%E5%88%99"><span class="toc-number">4.</span> <span class="toc-text">估计量的评选原则</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A0%E5%81%8F%E6%80%A7"><span class="toc-number">4.1.</span> <span class="toc-text">无偏性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E6%97%A0%E5%81%8F%E6%80%A7"><span class="toc-number">4.1.1.</span> <span class="toc-text">如何理解无偏性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%A0%E5%81%8F%E6%80%A7%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">4.1.2.</span> <span class="toc-text">无偏性的定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%AF%81%E6%98%8E%E6%97%A0%E5%81%8F%E6%80%A7%E6%9D%A5%E4%BF%A9%E4%BE%8B%E9%A2%98"><span class="toc-number">4.1.3.</span> <span class="toc-text">如何证明无偏性，来俩例题</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%81%E6%98%8E%E6%A0%B7%E6%9C%AC%E5%9D%87%E5%80%BCoverline-x%E6%80%BB%E6%98%AF%E6%80%BB%E4%BD%93%E5%9D%87%E5%80%BCex%E7%9A%84%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1%E9%87%8F"><span class="toc-number">4.1.3.1.</span> <span class="toc-text">证明样本均值$\overline X$总是总体均值EX的无偏估计量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AF%81%E6%98%8Es2-frac1n-1sum-x_i---barx2%E6%98%AFsigma-2%E7%9A%84%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1%E9%87%8F"><span class="toc-number">4.1.3.2.</span> <span class="toc-text">证明$S^2 &#x3D; \frac{1}{n-1}\sum (X_i -
\bar{X})^2$是σ2的无偏估计量</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%89%E6%95%88%E6%80%A7"><span class="toc-number">4.2.</span> <span class="toc-text">有效性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E6%9C%89%E6%95%88%E6%80%A7"><span class="toc-number">4.2.1.</span> <span class="toc-text">如何理解有效性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%89%E6%95%88%E6%80%A7%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">4.2.2.</span> <span class="toc-text">有效性的定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%89%E6%95%88%E6%80%A7%E8%AF%81%E6%98%8E%E7%9A%84%E4%BE%8B%E9%A2%98"><span class="toc-number">4.2.3.</span> <span class="toc-text">有效性证明的例题</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/58992.html" title="理解JavaLambda表达式的使用"><img src="/images/posts/cover_database2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="理解JavaLambda表达式的使用"/></a><div class="content"><a class="title" href="/posts/58992.html" title="理解JavaLambda表达式的使用">理解JavaLambda表达式的使用</a><time datetime="2025-07-03T02:25:28.000Z" title="发表于 2025-07-03 10:25:28">2025-07-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/14594.html" title="Java枚举类型及其深入理解"><img src="/images/posts/cover_docker2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Java枚举类型及其深入理解"/></a><div class="content"><a class="title" href="/posts/14594.html" title="Java枚举类型及其深入理解">Java枚举类型及其深入理解</a><time datetime="2025-07-03T02:06:05.000Z" title="发表于 2025-07-03 10:06:05">2025-07-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/4240.html" title="概率论与数理统计部分习题选做"><img src="/images/posts/cover_7x.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="概率论与数理统计部分习题选做"/></a><div class="content"><a class="title" href="/posts/4240.html" title="概率论与数理统计部分习题选做">概率论与数理统计部分习题选做</a><time datetime="2025-06-29T12:55:34.000Z" title="发表于 2025-06-29 20:55:34">2025-06-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/44212.html" title="魔女恋爱日记攻略"><div style="background: /images/posts/"></div></a><div class="content"><a class="title" href="/posts/44212.html" title="魔女恋爱日记攻略">魔女恋爱日记攻略</a><time datetime="2025-06-28T04:36:07.000Z" title="发表于 2025-06-28 12:36:07">2025-06-28</time></div></div></div></div></div></div></main><div class="fps-display"><span id="fps">FPS: 60</span></div><footer id="footer" style="background-image: url(/images/posts/cover_security.jpg);"><div id="footer-wrap"><div class="copyright">&copy;2024 - 2025 By ErgouTree</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div><div class="footer_custom_text">忘れたくない思い、ありますか？ <br>,<span id="realtime_duration" style="font-family: monospace;"></span>,<br><a href="https://icp.gov.moe/?keyword=20257009" target="_blank">萌ICP备20257009号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><a class="icon-V hidden" onclick="switchNightMode()" title="日间和夜间模式切换"><svg width="25" height="25" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon"></use></svg></a><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat-btn" type="button" title="聊天" style="display:none"><i class="fas fa-comment"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const applyThemeDefaultsConfig = theme => {
    if (theme === 'dark-mode') {
      Chart.defaults.color = "rgba(255, 255, 255, 0.8)"
      Chart.defaults.borderColor = "rgba(255, 255, 255, 0.2)"
      Chart.defaults.scale.ticks.backdropColor = "transparent"
    } else {
      Chart.defaults.color = "rgba(0, 0, 0, 0.8)"
      Chart.defaults.borderColor = "rgba(0, 0, 0, 0.1)"
      Chart.defaults.scale.ticks.backdropColor = "transparent"
    }
  }

  // Recursively traverse the config object and automatically apply theme-specific color schemes
  const applyThemeConfig = (obj, theme) => {
    if (typeof obj !== 'object' || obj === null) return

    Object.keys(obj).forEach(key => {
      const value = obj[key]
      // If the property is an object and has theme-specific options, apply them
      if (typeof value === 'object' && value !== null) {
        if (value[theme]) {
          obj[key] = value[theme] // Apply the value for the current theme
        } else {
          // Recursively process child objects
          applyThemeConfig(value, theme)
        }
      }
    })
  }

  const runChartJS = ele => {
    window.loadChartJS = true

    Array.from(ele).forEach((item, index) => {
      const chartSrc = item.firstElementChild
      const chartID = item.getAttribute('data-chartjs-id') || ('chartjs-' + index) // Use custom ID or default ID
      const width = item.getAttribute('data-width')
      const existingCanvas = document.getElementById(chartID)

      // If a canvas already exists, remove it to avoid rendering duplicates
      if (existingCanvas) {
          existingCanvas.parentNode.remove()
      }

      const chartDefinition = chartSrc.textContent
      const canvas = document.createElement('canvas')
      canvas.id = chartID

      const div = document.createElement('div')
      div.className = 'chartjs-wrap'

      if (width) {
        div.style.width = width
      }

      div.appendChild(canvas)
      chartSrc.insertAdjacentElement('afterend', div)

      const ctx = document.getElementById(chartID).getContext('2d')

      const config = JSON.parse(chartDefinition)

      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark-mode' : 'light-mode'

      // Set default styles (initial setup)
      applyThemeDefaultsConfig(theme)

      // Automatically traverse the config and apply dual-mode color schemes
      applyThemeConfig(config, theme)

      new Chart(ctx, config)
    })
  }

  const loadChartJS = () => {
    const chartJSEle = document.querySelectorAll('#article-container .chartjs-container')
    if (chartJSEle.length === 0) return

    window.loadChartJS ? runChartJS(chartJSEle) : btf.getScript('https://cdn.jsdelivr.net/npm/chart.js/dist/chart.umd.min.js').then(() => runChartJS(chartJSEle))
  }

  // Listen for theme change events
  btf.addGlobalFn('themeChange', loadChartJS, 'chartjs')
  btf.addGlobalFn('encrypt', loadChartJS, 'chartjs')

  window.pjax ? loadChartJS() : document.addEventListener('DOMContentLoaded', loadChartJS)
})()</script><script>(function() {
  const abcjsInit = function() {
    const abcjsFn = function() {
      setTimeout(function() {
        const sheets = document.querySelectorAll(".abc-music-sheet")
        for (let i = 0; i < sheets.length; i++) {
          const ele = sheets[i]
          if (ele.children.length > 0) continue

          // Parse parameters from data-params attribute
          let params = {}
          const dp = ele.getAttribute("data-params")
          if (dp) {
            try {
              params = JSON.parse(dp)
            } catch (e) {
              console.error("Failed to parse data-params:", e)
            }
          }

          // Merge parsed parameters with the responsive option
          // Ensures params content appears before responsive
          const options = { ...params, responsive: "resize" }

          // Render the music score using ABCJS.renderAbc
          ABCJS.renderAbc(ele, ele.innerHTML, options)
        }
      }, 100)
    }

    if (typeof ABCJS === "object") {
      abcjsFn()
    } else {
      btf.getScript("https://cdn.jsdelivr.net/npm/abcjs/dist/abcjs-basic-min.min.js").then(abcjsFn)
    }
  }

  if (window.pjax) {
    abcjsInit()
  } else {
    window.addEventListener("load", abcjsInit)
  }

  btf.addGlobalFn("encrypt", abcjsInit, "abcjs")
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = {"labels":["Gitalk","Comment"],"createIssueManually":false,"distractionFreeMode":false}

  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  const initGitalk = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyGitalk = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const gitalk = new Gitalk({
      clientID: 'Ov23li3vDQANiUddL4XB',
      clientSecret: '5c9a56d02995340fca117809cd414662aadce6ff',
      repo: 'HexoComment',
      owner: 'ergou10086',
      admin: ['ergou10086'],
      updateCountCallback: commentCount,
      ...option,
      id: isShuoshuo ? path : (option && option.id) || '93157a7f650fe15aac82080d0f9a9aa3'
    })

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async(el, path) => {
    if (typeof Gitalk === 'function') initGitalk(el, path)
    else {
      await btf.getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await btf.getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk(el, path)
    }
  }

  if (isShuoshuo) {
    'Gitalk' === 'Gitalk'
      ? window.shuoshuoComment = { loadComment: loadGitalk }
      : window.loadOtherComment = loadGitalk
    return
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><div class="aplayer no-destroy" data-id="13587761608" data-server="netease" data-type="playlist" data-fixed="true" data-autoplay="false" data-lrcType="-1"> </div><script src="https://cdn.jsdelivr.net/npm/abcjs@7.1.2/dist/abcjs-basic-min.js"></script><script src="/js/sun_moon.js" async></script><script src="https://cdn.jsdelivr.net/npm/dayjs@1.11.7/dayjs.min.js"></script><script src="https://cdn.jsdelivr.net/npm/dayjs@1.11.7/plugin/duration.min.js"></script><script src="/scripts/realtime.js"></script><script src="/scripts/random.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="null" data-click="true"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script>(() => {
  window.ChatraID = '4bzb546NSBoJcrNyu'
  window.Chatra = window.Chatra || function() {
    (window.Chatra.q = window.Chatra.q || []).push(arguments)
  }

  btf.getScript('https://call.chatra.io/chatra.js').then(() => {
    const isChatBtn = true
    const isChatHideShow = true

    if (isChatBtn) {
      const close = () => {
        Chatra('minimizeWidget')
        Chatra('hide')
      }

      const open = () => {
        Chatra('openChat', true)
        Chatra('show')
      }

      window.ChatraSetup = { startHidden: true }
    
      window.chatBtnFn = () => document.getElementById('chatra').classList.contains('chatra--expanded') ? close() : open()

      document.getElementById('chat-btn').style.display = 'block'
    } else if (isChatHideShow) {
      window.chatBtn = {
        hide: () => Chatra('hide'),
        show: () => Chatra('show')
      }
    }
  })
})()</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script>(() => {
  const destroyAplayer = () => {
    if (window.aplayers) {
      for (let i = 0; i < window.aplayers.length; i++) {
        if (!window.aplayers[i].options.fixed) {
          window.aplayers[i].destroy()
        }
      }
    }
  }

  const runMetingJS = () => {
    typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()
  }

  btf.addGlobalFn('pjaxSend', destroyAplayer, 'destroyAplayer')
  btf.addGlobalFn('pjaxComplete', loadMeting, 'runMetingJS')
})()</script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"]):not([href="/music/"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => fn())
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      const usePjax = true
      true 
        ? (usePjax ? pjax.loadUrl('/404.html') : window.location.href = '/404.html')
        : window.location.href = e.request.responseURL
    }
  })
})()</script><script src="/js/fps-display.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/7844.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src="/images/posts/cover_database.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-05-14</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/7844.html&quot;);" href="javascript:void(0);" alt="">结构化查询语言SQL</a><div class="blog-slider__text">SQL基本很常用的语句都在这里了，本质上是当初为了应付数据库考试整理的，后来发现还蛮有用的很方便查常用的语句</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/7844.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/39918.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src="/images/posts/cover_java4.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-05-22</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/39918.html&quot;);" href="javascript:void(0);" alt="">SpringBoot part0?INF-SpringBoot这个框架都需要学习什么</a><div class="blog-slider__text">主要围绕Spring Boot中重要知识来简洁或详细的说明，其中部分不够完全，持续更新</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/39918.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/42179.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src="/images/posts/cover_java11.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-05-15</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/42179.html&quot;);" href="javascript:void(0);" alt="">关于Lombok在高版本IDEA中注解处理不生效的问题解决</a><div class="blog-slider__text">基本上是彻底的解决了用 IDEA 新建 Spring Boot 项目时候会产生的 Lombok 注解处理失效的各种问题</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/42179.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/40344.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src="/images/posts/cover_实用.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-05-05</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/40344.html&quot;);" href="javascript:void(0);" alt="">个人向galgame原声带或相关音乐整理及其资源</a><div class="blog-slider__text">整理了我喜欢的galgame ost或者衍生的音乐专辑，部分资源是自己扒盘扒下来的，部分来自鸟白岛放映厅</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/40344.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/6458.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src="/images/posts/cover_math.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-05-17</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/6458.html&quot;);" href="javascript:void(0);" alt="">对书上证明样本方差是总体方差的无偏估计量的解析</a><div class="blog-slider__text">对书上证明样本方差是总体方差的无偏估计量的解析，高等教育出版社-华科大版本</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/6458.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/12811.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src="/images/posts/cover_alog.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-04-24</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/12811.html&quot;);" href="javascript:void(0);" alt="">第十五届蓝桥杯Java国赛B组D题-园丁题解</a><div class="blog-slider__text">第十五届蓝桥杯Java国赛B组D题-园丁题解，该题解已经发布到洛谷社区中并且被全站推荐</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/12811.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/27893.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src="/images/posts/cover_java4.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-04-29</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/27893.html&quot;);" href="javascript:void(0);" alt="">操作系统之处理机的死锁部分概述</a><div class="blog-slider__text">对操作系统之处理机的死锁部分知识的总结，包括代码复现</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/27893.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/28134.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src="/images/posts/cover_lb.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-05-09</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/28134.html&quot;);" href="javascript:void(0);" alt="">Little Busters!EX游戏攻略</a><div class="blog-slider__text">整理了一份详细清晰的Little Busters！EX的游戏攻略，因为我自己也在推，就顺手整理了一份方便查阅的md文档</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/28134.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" onclick="pjax.loadUrl(&quot;posts/9323.html&quot;);" href="javascript:void(0);" alt=""><img width="48" height="48" src="/images/posts/cover_java9.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2025-05-16</span><a class="blog-slider__title" onclick="pjax.loadUrl(&quot;posts/9323.html&quot;);" href="javascript:void(0);" alt="">Spring Boot中使用Hibernate框架</a><div class="blog-slider__text">对学习完Hibernate的应用部分，主要围绕Spring Boot中使用Hibernate框架，建议学习完 Hibernate 框架再看</div><a class="blog-slider__button" onclick="pjax.loadUrl(&quot;posts/9323.html&quot;);" href="javascript:void(0);" alt="">详情       </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>